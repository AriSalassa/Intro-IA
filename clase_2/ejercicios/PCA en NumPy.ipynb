{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Implementación de PCA en NumPy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Objetivos\n",
    "* Implementación de PCA en NumPy paso a paso\n",
    "* Comparación de resultados con Scikit-learn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementación"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Dado un dataset $X \\in \\mathbb{R}^{n, d}$, con $n$ muestras y $d$ features, queremos reducir sus dimensiones a $m$. Para ello, el primer paso es centrar el dataset (Hint: usen np.mean)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# cantidad de muestras\n",
    "n = 100\n",
    "\n",
    "# dimensión inicial\n",
    "m = 3\n",
    "\n",
    "# dimensión reducida\n",
    "d = 2\n",
    "\n",
    "\n",
    "# Muestra random\n",
    "X_1 = np.random.normal(loc=[-5, -5, -5], scale=[1, 10, 5], size=(int(n/4),m))\n",
    "X_2 = np.random.normal(loc=[1, 1, 1], scale=[1, 10, 5], size=(int(n/4),m))\n",
    "X_3 = np.random.normal(loc=[-10, 10, 10], scale=[1, 10, 5], size=(int(n/4),m))\n",
    "X_4 = np.random.normal(loc=[1, -2, 3], scale=[2, 2, 2], size=(int(n/4),m))\n",
    "\n",
    "X = np.concatenate((X_1, X_2, X_3, X_4))\n",
    "print(\"X shape:\")\n",
    "print(X.shape)\n",
    "print(\"X head:\")\n",
    "print(X[:5,:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape:\n",
      "(100, 3)\n",
      "X head:\n",
      "[[ -3.87333239 -14.72777593   1.06263634]\n",
      " [ -6.35196476   7.00345829 -13.48017221]\n",
      " [ -5.80403836 -10.57548385 -14.36992022]\n",
      " [ -5.09108229   1.31845882  -9.71189046]\n",
      " [ -5.59589367 -11.98410246  -7.34810483]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "X_mean = X.mean(axis=0)\n",
    "X_centered = X - X_mean"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Obtener la matriz de covarianza de $X^T$, revisar en la teoría por qué utilizamos la transpuesta. Buscar en la documentación de NumPy qué funciones se pueden utilizar."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "cov_mtx = np.cov(X_centered.T) # Nos interesa saber cuál es la covarianza de las features, no de las realizaciones.\n",
    "cov_mtx.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Calcular los autovalores y autovectores de la matriz de covarianza. Revisar la documentación de NumPy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "eig_w, eig_v = np.linalg.eig(cov_mtx)\n",
    "print(eig_w)\n",
    "print(eig_v)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[119.7731195   16.67964837  44.54499189]\n",
      "[[ 0.17702684 -0.96788551 -0.17849129]\n",
      " [-0.94081145 -0.11315804 -0.31948249]\n",
      " [-0.28902475 -0.22448363  0.93062978]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Ordernar los autovectores en el sentido de los autovalores decrecientes, revisar la teoría de ser necesario."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "arg_sort = np.argsort(eig_w)[::-1]\n",
    "eig_w = eig_w[arg_sort]\n",
    "eig_v = eig_v[:,arg_sort]\n",
    "print(eig_w)\n",
    "print(eig_v)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[119.7731195   44.54499189  16.67964837]\n",
      "[[ 0.17702684 -0.17849129 -0.96788551]\n",
      " [-0.94081145 -0.31948249 -0.11315804]\n",
      " [-0.28902475  0.93062978 -0.22448363]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Proyectar el dataset centrado sobre los $m$ autovectores más relevantes (Hint: usen np.dot)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "proj = X.dot(eig_v[:,:d])\n",
    "print(proj.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Consolidar los pasos anteriores en una función o clase PCA."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "def custom_pca(X, num_comp=2):\n",
    "    X = X - X.mean(axis=0)\n",
    "    cov_mtx = np.cov(X.T)\n",
    "\n",
    "    eig_w, eig_v = np.linalg.eig(cov_mtx)\n",
    "\n",
    "    arg_sort = np.argsort(eig_w)[::-1]\n",
    "    eig_w = eig_w[arg_sort]\n",
    "    eig_v = eig_v[:,arg_sort]\n",
    "\n",
    "    proj = X.dot(eig_v[:,:num_comp])\n",
    "    proj_v = eig_v[:num_comp]\n",
    "\n",
    "    return proj_v, proj"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Comparar los resultados obtenidos con el modelo de PCA implementado en Scikit-learn ([ver documentación](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)). Tomar como dataset:\n",
    "\n",
    "$X=\\begin{bmatrix}\n",
    "0.8 & 0.7\\\\\n",
    "0.1 & -0.1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Se debe reducir a un componente. Verificar los resultados con np.testing.assert_allclose"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "X_test = np.array([[0.8, 0.7], [0.1, -0.1]])\n",
    "X_scaled = StandardScaler(with_std=False).fit_transform(X_test)\n",
    "X_scaled"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.35,  0.4 ],\n",
       "       [-0.35, -0.4 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "pca_skl = PCA(n_components=1)\n",
    "pca_skl.fit(X_scaled)\n",
    "X_pca_skl = pca_skl.transform(X_scaled)\n",
    "X_pca_skl"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.53150729],\n",
       "       [ 0.53150729]])"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "eig_v, X_pca_cust = custom_pca(X_test, 1)\n",
    "X_pca_cust"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.53150729],\n",
       "       [ 0.53150729]])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "np.testing.assert_allclose(X_pca_skl, X_pca_cust)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "00dfc0830a513947b60a95c876dfb43a1534c820f0c320933420ad340a02dc2c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}